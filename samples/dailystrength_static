import requests
from bs4 import BeautifulSoup

# URL of the webpage
url = "https://www.dailystrength.org/search?query=pain%20management"

# Send an HTTP GET request
response = requests.get(url)

# Check if the request was successful
if response.status_code == 200:
    # Parse the HTML content of the page
    soup = BeautifulSoup(response.content, 'html.parser')

    # Find all elements with class "newsfeed__item"
    elements = soup.find_all('li', class_='newsfeed__item')

    # List to store the scraped links
    links = []

    # Extract and store the links
    for element in elements:
        link = element.find('h2', class_='newsfeed__title').find('a')['href']
        full_link = f"https://www.dailystrength.org{link}"
        links.append(full_link)

    # Print the list of links
    for link in links:
        print(link)
else:
    print(f"Failed to retrieve the webpage. Status code: {response.status_code}")
