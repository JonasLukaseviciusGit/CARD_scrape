import time
import json
import random
from selenium import webdriver
import re

# Set up the Selenium WebDriver
driver = webdriver.Chrome()

# Define the URL you want to scrape
url = 'https://www.quora.com/search?q=did%20nazis%20escape%20to%20Argentina'

# Send an HTTP GET request with headers
driver.get(url)

# Define a regular expression pattern to match Quora URLs
pattern = r'https://www\.quora\.com/[a-zA-Z0-9_-]+(?=[^a-zA-Z0-9_-]|$)'

# Wait for the page to load (you might need to adjust the sleep duration)
time.sleep(2)

# Initialize a list to store matched URLs
matches = []

# Scroll down 10 times to load more elements
scroll_count = 0
while scroll_count < 10:
    # Execute a JavaScript command to scroll down the page
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")

    # Print the current scroll count
    print(f'Scrolling {scroll_count + 1}')

    # Generate a random sleep time between 1 and 3 seconds
    sleep_time = random.uniform(1, 3)
    time.sleep(sleep_time)

    # Extract all matching URLs from the current page content
    response = driver.page_source
    new_matches = re.findall(pattern, response)

    # Add the new matches to the list of URLs
    matches.extend(new_matches)

    # Increment the scroll count
    scroll_count += 1

# Close the browser
driver.quit()

# Save the complete list to a JSON file
output_path = r'C:\Users\HP\Desktop\CARD\quora\posts.json'
with open(output_path, 'w') as json_file:
    json.dump(matches, json_file, indent=2)

# Print the matched URLs
for url in matches:
    print(url)

print(f"Results saved to {output_path}")
